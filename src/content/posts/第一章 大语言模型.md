---
title: "第一章 大语言模型"
description: "本章介绍了什么是大语言模型、Tokens以及提问范式"
published: 2026-01-23
pubDate: 2026-01-23
date: 2025-01-23
draft: false
tags: ["LLM", "Python", "LLM QA System"]
category: "大模型应用"
author: "0x3a0"
sourceLink: "https://github.com/0x3a0/blog/src/posts/第一章 大语言模型.md"
---

# 语言模型的Token和提问范式
## 一、语言模型
**大语言模型(Large Language Model - LLM)** 是通过数百亿的大规模文本数据集进行训练的。大模型会根据当前输入的上下文预测下一个词的概率分布，通过比较模型预测和实际的下一个词，更新大模型参数使预测和实际两者的差异最小化，不断的反复训练促使模型参数收敛，使其预测能力不断提高。  
LLM主要可以分为两类：**基础语言模型(Base LLM)** 和**指令微调语言模型(Instruction Tuned LLM)** 

1. 基础语言模型(Base LLM)：使用常规的训练方式，通过反复预测下一个词来训练的方式进行训练。当基础语言模型在某些未见过的文本数据上进行回复时，可能会通过自由联想生成戏剧化的内容，这种现象也称模型幻觉。
2. 指令微调语言模型(Instruction Tuned LLM)：对模型进行了专门的训练，以便更好地理解问题并给出符合指令的回答。因此，**指令微调语言模型更适合任务导向的对话应用**，可以生成准确的回复，而非自由联想。

## 二、Tokens
对LLM进行深入的学习后会发现，LLM实际上并不是重复预测下一个词，而是重复预测下一个**token**。对于一个句子，LLM会先使用 **分词器(Tokenizer)** 将其拆分为一个个token，这样可以大幅提高模型训练和推断的效率。对于英文输入，一个 token 一般对应 4 个字符或者四分之三个单词；对于中文输入，一个 token 一般对应一个或半个词。不同模型有不同的 token 限制，token 限制指的是输入的 Prompt 和输出的 Completion 的 token 数之和。

## 三、提问范式
使用`system`、`assistant`、`user`区分“系统消息”，“助手消息”，“用户消息”三个部分，规范Prompt的编写

